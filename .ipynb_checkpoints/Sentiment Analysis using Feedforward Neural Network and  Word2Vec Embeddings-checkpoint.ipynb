{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c9255b5-32d5-4b81-becd-8a079fb38c4f",
   "metadata": {},
   "source": [
    "# **Sentiment Analysis using Feedforward Neural Network and Word2Vec Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bf203d-110b-468b-9f21-45bc497f1d39",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91dea301-b230-4752-b425-b3eceb94f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import gensim.downloader as api\n",
    "import warnings\n",
    "\n",
    "nltk.download('stopwords',quiet = True)\n",
    "nltk.download('wordnet',quiet = True)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e60b9b-048f-4056-a09c-030859127039",
   "metadata": {},
   "source": [
    "### **Importing Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09841cb5-4da1-4a4c-897f-d5a669007bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./SentimentData.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf9a34f-76ae-416c-85c9-0c6fd58f6de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12589</th>\n",
       "      <td>The Japanese \"Run Lola Run,\" his is one offbea...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>It must have been excruciating to attend the d...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41657</th>\n",
       "      <td>So, where are the cannibals? Those intrigued b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15098</th>\n",
       "      <td>Just read through the other comments here, and...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48994</th>\n",
       "      <td>Rarely does one find a movie so bad that it ac...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32412</th>\n",
       "      <td>It's refreshing to see a movie that you think ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38907</th>\n",
       "      <td>I too had waited a long time to see this film....</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35012</th>\n",
       "      <td>I never met a single person (out of hundreds) ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6764</th>\n",
       "      <td>After the mysterious death of an old friend,a ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43324</th>\n",
       "      <td>It was agonizingly bad movie. It will eat your...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "12589  The Japanese \"Run Lola Run,\" his is one offbea...  positive\n",
       "3511   It must have been excruciating to attend the d...  negative\n",
       "41657  So, where are the cannibals? Those intrigued b...  negative\n",
       "15098  Just read through the other comments here, and...  negative\n",
       "48994  Rarely does one find a movie so bad that it ac...  negative\n",
       "32412  It's refreshing to see a movie that you think ...  positive\n",
       "38907  I too had waited a long time to see this film....  negative\n",
       "35012  I never met a single person (out of hundreds) ...  positive\n",
       "6764   After the mysterious death of an old friend,a ...  negative\n",
       "43324  It was agonizingly bad movie. It will eat your...  negative"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f412b90b-6993-40fd-a8f5-556a501269fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce4ec45-50e0-4bd4-8d43-8de3156b9208",
   "metadata": {},
   "source": [
    "### **Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eef528de-c43c-41f7-a04a-0f5a42e6292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    #Removing special characters, punctuation, numbers, URLs, and extra spaces.\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)#Removes URLs from the given text.\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)#Removes special characters, punctuations, numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()#Removes extra spaces\n",
    "\n",
    "    #Converting all text to lower case.\n",
    "    text = text.lower()\n",
    "\n",
    "    #Splitting the text into individual tokens (words).\n",
    "    tokens = text.split()\n",
    "\n",
    "    #Removing common stopwords (for example, ”the”, ”of”, ”and”,...).\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    #Coverting verbs into their base forms.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#Preprocessing the 'Reviews' in the data frame and storing them.\n",
    "data['preprocessed_reviews'] = data['review'].apply(preprocess_text)\n",
    "\n",
    "# Convert sentiment labels from categorical strings to numerical values\n",
    "# Mapping: 'positive' -> 1, 'negative' -> 0\n",
    "data['sentiment'] = data['sentiment'].map({'positive': 1, 'negative': 0})  # Adjust the mapping as needed based on your actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97433b64-ab93-4d7b-8878-49c3ef65d54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>preprocessed_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14412</th>\n",
       "      <td>Jon Voight plays a man named Joe. Joe is shook...</td>\n",
       "      <td>1</td>\n",
       "      <td>jon voight play man named joe joe shook haunti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26100</th>\n",
       "      <td>This film is a travesty, and isn't fit to keep...</td>\n",
       "      <td>0</td>\n",
       "      <td>film travesty isnt fit keep company superior o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>Keys to the VIP is just another one of the hor...</td>\n",
       "      <td>0</td>\n",
       "      <td>key vip another one horrible tv show see stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19420</th>\n",
       "      <td>Pressburger and Powell's greatest movie. David...</td>\n",
       "      <td>1</td>\n",
       "      <td>pressburger powell greatest movie david niven ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41907</th>\n",
       "      <td>The morbid Catholic writer Gerard Reve (Jeroen...</td>\n",
       "      <td>1</td>\n",
       "      <td>morbid catholic writer gerard reve jeroen krab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9316</th>\n",
       "      <td>The decline series is amazing and director PS ...</td>\n",
       "      <td>1</td>\n",
       "      <td>decline series amazing director p cant get eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33000</th>\n",
       "      <td>I was permanently scarred by this terrible fil...</td>\n",
       "      <td>0</td>\n",
       "      <td>permanently scarred terrible filmbr br main ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12775</th>\n",
       "      <td>I saw this movie for the first time on a sick ...</td>\n",
       "      <td>1</td>\n",
       "      <td>saw movie first time sick day school ten year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5895</th>\n",
       "      <td>First and foremost I am a gay man, although do...</td>\n",
       "      <td>0</td>\n",
       "      <td>first foremost gay man although live life with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>Lovely piece of good cinema. This is one of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>lovely piece good cinema one film see smiling ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment  \\\n",
       "14412  Jon Voight plays a man named Joe. Joe is shook...          1   \n",
       "26100  This film is a travesty, and isn't fit to keep...          0   \n",
       "6096   Keys to the VIP is just another one of the hor...          0   \n",
       "19420  Pressburger and Powell's greatest movie. David...          1   \n",
       "41907  The morbid Catholic writer Gerard Reve (Jeroen...          1   \n",
       "9316   The decline series is amazing and director PS ...          1   \n",
       "33000  I was permanently scarred by this terrible fil...          0   \n",
       "12775  I saw this movie for the first time on a sick ...          1   \n",
       "5895   First and foremost I am a gay man, although do...          0   \n",
       "3489   Lovely piece of good cinema. This is one of th...          1   \n",
       "\n",
       "                                    preprocessed_reviews  \n",
       "14412  jon voight play man named joe joe shook haunti...  \n",
       "26100  film travesty isnt fit keep company superior o...  \n",
       "6096   key vip another one horrible tv show see stati...  \n",
       "19420  pressburger powell greatest movie david niven ...  \n",
       "41907  morbid catholic writer gerard reve jeroen krab...  \n",
       "9316   decline series amazing director p cant get eno...  \n",
       "33000  permanently scarred terrible filmbr br main ac...  \n",
       "12775  saw movie first time sick day school ten year ...  \n",
       "5895   first foremost gay man although live life with...  \n",
       "3489   lovely piece good cinema one film see smiling ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ad1df-bf61-478b-bc15-e7f939da95bb",
   "metadata": {},
   "source": [
    "### **Word Embeddings with Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae0d0b70-ae01-41bb-9ad6-d5b7ea2b91bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>preprocessed_reviews</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31789</th>\n",
       "      <td>I was going to use 'The German Scream' as a su...</td>\n",
       "      <td>1</td>\n",
       "      <td>going use german scream summary already taken ...</td>\n",
       "      <td>[0.059794337, 0.020221801, -5.5403934e-06, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30397</th>\n",
       "      <td>After being forced to sit through some real st...</td>\n",
       "      <td>1</td>\n",
       "      <td>forced sit real stinker racing stripe shark bo...</td>\n",
       "      <td>[0.07020223, 0.011536153, 0.03207957, 0.091129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18471</th>\n",
       "      <td>We can start with the wooden acting but this f...</td>\n",
       "      <td>0</td>\n",
       "      <td>start wooden acting film disaster grown ny tel...</td>\n",
       "      <td>[0.044482287, 0.020468945, 0.025942635, 0.0817...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19857</th>\n",
       "      <td>This game is one of the best RPG. Fist, It is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>game one best rpg fist actually amusing battle...</td>\n",
       "      <td>[0.089101896, 0.043404475, 0.019463645, 0.0744...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>For me personally this film goes down in my to...</td>\n",
       "      <td>1</td>\n",
       "      <td>personally film go top four time exception jam...</td>\n",
       "      <td>[0.036895655, 0.025342613, -0.03427226, 0.0757...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25590</th>\n",
       "      <td>Quentin in my opinion has written and directed...</td>\n",
       "      <td>0</td>\n",
       "      <td>quentin opinion written directed really one go...</td>\n",
       "      <td>[0.060750842, -0.00020087519, -0.021714706, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35994</th>\n",
       "      <td>This is the ultimate Kung Fu movie! This is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>ultimate kung fu movie kung fu movie kung fu m...</td>\n",
       "      <td>[0.08563451, 0.025835427, -0.0016312461, 0.100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30877</th>\n",
       "      <td>I had to watch this film because the plot was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>watch film plot outrageous film lived expectat...</td>\n",
       "      <td>[0.077582434, 0.028249007, 0.013588538, 0.0659...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32857</th>\n",
       "      <td>Forget about the plot of this movie. Forget ab...</td>\n",
       "      <td>1</td>\n",
       "      <td>forget plot movie forget fact wonderfully acte...</td>\n",
       "      <td>[0.06402447, 0.0041672927, 0.011843051, 0.0707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8952</th>\n",
       "      <td>I really do not know what people have against ...</td>\n",
       "      <td>1</td>\n",
       "      <td>really know people film definitely one favouri...</td>\n",
       "      <td>[0.054865334, 0.023559848, -0.009990472, 0.085...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment  \\\n",
       "31789  I was going to use 'The German Scream' as a su...          1   \n",
       "30397  After being forced to sit through some real st...          1   \n",
       "18471  We can start with the wooden acting but this f...          0   \n",
       "19857  This game is one of the best RPG. Fist, It is ...          1   \n",
       "4835   For me personally this film goes down in my to...          1   \n",
       "25590  Quentin in my opinion has written and directed...          0   \n",
       "35994  This is the ultimate Kung Fu movie! This is th...          0   \n",
       "30877  I had to watch this film because the plot was ...          0   \n",
       "32857  Forget about the plot of this movie. Forget ab...          1   \n",
       "8952   I really do not know what people have against ...          1   \n",
       "\n",
       "                                    preprocessed_reviews  \\\n",
       "31789  going use german scream summary already taken ...   \n",
       "30397  forced sit real stinker racing stripe shark bo...   \n",
       "18471  start wooden acting film disaster grown ny tel...   \n",
       "19857  game one best rpg fist actually amusing battle...   \n",
       "4835   personally film go top four time exception jam...   \n",
       "25590  quentin opinion written directed really one go...   \n",
       "35994  ultimate kung fu movie kung fu movie kung fu m...   \n",
       "30877  watch film plot outrageous film lived expectat...   \n",
       "32857  forget plot movie forget fact wonderfully acte...   \n",
       "8952   really know people film definitely one favouri...   \n",
       "\n",
       "                                              embeddings  \n",
       "31789  [0.059794337, 0.020221801, -5.5403934e-06, 0.0...  \n",
       "30397  [0.07020223, 0.011536153, 0.03207957, 0.091129...  \n",
       "18471  [0.044482287, 0.020468945, 0.025942635, 0.0817...  \n",
       "19857  [0.089101896, 0.043404475, 0.019463645, 0.0744...  \n",
       "4835   [0.036895655, 0.025342613, -0.03427226, 0.0757...  \n",
       "25590  [0.060750842, -0.00020087519, -0.021714706, 0....  \n",
       "35994  [0.08563451, 0.025835427, -0.0016312461, 0.100...  \n",
       "30877  [0.077582434, 0.028249007, 0.013588538, 0.0659...  \n",
       "32857  [0.06402447, 0.0041672927, 0.011843051, 0.0707...  \n",
       "8952   [0.054865334, 0.023559848, -0.009990472, 0.085...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the pre-trained Word2Vec model (Google News)\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Function to create embeddings\n",
    "def get_review_embedding(review):\n",
    "    words = review.split()  # Assuming the reviews are space-separated\n",
    "    word_vectors = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in model:  # Check if the word is in the model\n",
    "            word_vectors.append(model[word])\n",
    "    \n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)  # Average vector\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Zero vector if no words are found\n",
    "\n",
    "# Apply the function to create word embeddings\n",
    "data['embeddings'] = data['preprocessed_reviews'].apply(get_review_embedding)\n",
    "\n",
    "#Displaying the data frame after creating embeddings for processed reviews\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19cde18f-3e11-4c9d-9e10-ec6a269b50bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['embeddings'][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c1916-24cd-4bb5-9e21-b69b098e105e",
   "metadata": {},
   "source": [
    "### **Splitting the dataset into training, testing and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b96d623-d0f3-4e40-84fa-450a79a02957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset\n",
    "X = np.array(data['embeddings'].tolist())\n",
    "y = np.array(data['sentiment'])\n",
    "# Split the dataset\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f43ac0-8e69-4df4-8a04-08d8dc3a19ac",
   "metadata": {},
   "source": [
    "### **Building and training Feed Forward Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eeb3b4f5-0135-4967-a9a3-18e0ae04af4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7971 - loss: 0.4346 - val_accuracy: 0.8195 - val_loss: 0.4138\n",
      "Epoch 2/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.3530 - val_accuracy: 0.8321 - val_loss: 0.3689\n",
      "Epoch 3/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8502 - loss: 0.3460 - val_accuracy: 0.8513 - val_loss: 0.3425\n",
      "Epoch 4/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8594 - loss: 0.3339 - val_accuracy: 0.8160 - val_loss: 0.3941\n",
      "Epoch 5/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 0.3333 - val_accuracy: 0.8493 - val_loss: 0.3431\n",
      "Epoch 6/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.3196 - val_accuracy: 0.8497 - val_loss: 0.3396\n",
      "Epoch 7/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8652 - loss: 0.3149 - val_accuracy: 0.8529 - val_loss: 0.3363\n",
      "Epoch 8/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8683 - loss: 0.3058 - val_accuracy: 0.8564 - val_loss: 0.3376\n",
      "Epoch 9/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.3044 - val_accuracy: 0.8552 - val_loss: 0.3331\n",
      "Epoch 10/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8733 - loss: 0.2971 - val_accuracy: 0.8496 - val_loss: 0.3400\n",
      "Epoch 11/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 0.2913 - val_accuracy: 0.8515 - val_loss: 0.3356\n",
      "Epoch 12/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.2861 - val_accuracy: 0.8431 - val_loss: 0.3571\n",
      "Epoch 13/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8807 - loss: 0.2797 - val_accuracy: 0.8532 - val_loss: 0.3455\n",
      "Epoch 14/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8864 - loss: 0.2681 - val_accuracy: 0.8527 - val_loss: 0.3356\n",
      "Epoch 15/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8903 - loss: 0.2611 - val_accuracy: 0.8543 - val_loss: 0.3433\n",
      "Epoch 16/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8922 - loss: 0.2538 - val_accuracy: 0.8456 - val_loss: 0.3591\n",
      "Epoch 17/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.2488 - val_accuracy: 0.8424 - val_loss: 0.3673\n",
      "Epoch 18/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 0.2434 - val_accuracy: 0.8460 - val_loss: 0.3771\n",
      "Epoch 19/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8996 - loss: 0.2365 - val_accuracy: 0.8445 - val_loss: 0.3846\n",
      "Epoch 20/20\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9006 - loss: 0.2310 - val_accuracy: 0.8537 - val_loss: 0.4087\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(300,)),  # Adjust for your embedding size\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=20,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe280dcd-efde-47ed-8d25-ed0c411ab407",
   "metadata": {},
   "source": [
    "### **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98522c86-151a-4a40-8f01-5d5bfd780dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy on D_test: 0.8593\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3771\n",
      "Test Loss: 0.3927\n",
      "Test Accuracy: 0.8593\n"
     ]
    }
   ],
   "source": [
    "# Get predicted probabilities\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# True labels (ensure y_test is in the same format)\n",
    "# Assuming y_test is already binary (0 or 1)\n",
    "\n",
    "# Calculate the accuracy\n",
    "correct_predictions = np.sum(y_pred.flatten() == y_test.flatten())  # Count correct predictions\n",
    "T = len(y_test)  # Total number of instances in the test set\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / T\n",
    "\n",
    "print(f\"Accuracy on D_test: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
